Wang_em_gaussion

Content list:
1. README
2. wang_em_gaussian.py
3. Screenshots of the experiment(manipulate --cluster_num, --iterations, --tied, --clusters_file)


Experiment and interpretation:

1. manipulating --cluster_num from 1 to 10 while keeping --iterations = 100, covariance separated. The log likelihood converged around -4.35(Train) and -4.32(Dev) when cluster_num >=4, see screenshot "Log Likelihood Vs Cluster Number - Separated Covariance.png", detail results are as blow in the third part.


2. manipulating --iterations from 1 to 100 while keeping --cluster_num = 5 (because >=4 it converges), covariance separated. The log likelihood converged around -4.35(Train) and -4.33(Dev) when iterations >=20, see screenshot "Log Likelihood Vs Iterations - Separated Covariance.png", detail results are as blow in the third part.

When covariance is separated, the log likelihood converged -4.35(Train) and -4.32(Dev) when cluster_num >=4 and iterations >=20.

3. set covariance = tied, cluster_num= 5, changed iterations from 1 to 100. The log likelihood converged around -10.58(Train and Dev) when iterations >=2, see screenshot Log Likelihood Vs Iterations - Tied Covariance.png", detail results are as blow in the third part.

The tied covariance looks did worse performance comparing with separated covariance giving the same setting for the cluster_num and iterations.

4. set --iteration 20 --print_params --clusters_file gaussian_smoketest_clusters.txt. When iterations >= 10, the log likelihood converged around Train+ll = -4.55, Dev_ll = -4.65. detail results are as blow in the third part. Using the cluster_file to initialize the model also can reach to the optimal results by less iterations.

5. Set wang_em_gaussian.py --nodev --iterations 100 --print_params --clusters_file gaussian_smoketest_clusters.txt. output result with no develop data. Tain ll  os around -4.55



Results record:

1. Run 'wang_em_gaussian.py --cluster_num 10 --iterations 100 --print_params'
Gaussian
Train LL: -4.338218671275782
Dev LL: -4.34300028226051
Lambdas: 0.03919663658983295 | 0.05183957983837139 | 0.054581816885623906 | 0.12304758526120825 | 0.08489892523780215 | 0.04155252058148858 | 0.11645639243081099 | 0.20161195725253606 | 0.23650018725074365 | 0.05031439867158205
Mus: -0.22782545499144422 0.6675517899396365 | -0.41084938268268945 -3.5916734879157817 | -1.9404006564957843 -1.2480780642501825 | 0.18978832207363527 2.348192219968684 | 4.133958951322062 -2.191442315317296 | -0.23175483443203002 -1.6557745984618246 | 0.03690691425340763 1.404995460264727 | -0.7339322069039571 -3.383712425510112 | -3.874933009676357 0.05801164334321419 | 0.050079962720189594 2.0937697463941465
Sigmas: 1.022514989993058 0.594115488363792 0.594115488363792 2.2934175983854224 | 0.4575692767272496 0.27724185657009764 0.27724185657009764 2.9321592654480364 | 0.8102771082927476 1.935866951881351 1.935866951881351 5.562541581310685 | 0.9998138313601052 0.3611215266727848 0.3611215266727848 1.1554882915986984 | 0.6760754505545707 -0.015579877424864289 -0.015579877424864294 3.3620325761844962 | 9.528539756489842 0.4802541392429166 0.4802541392429166 0.18641965349868655 | 0.7589165809843322 0.06723229854448406 0.06723229854448409 0.8767111037214541 | 4.680090382646209 -1.8753048210546641 -1.875304821054664 2.7322185375712396 | 5.561434445476165 2.392721452382553 2.3927214523825526 1.2223253246093897 | 1.7808884446798272 -0.5339218938573581 -0.5339218938573581 0.33298024319663183



2. manipulating --cluster_num from 1 to 10 while keeping --iterations = 100, covariance seperated

Train_LL = np.array([-4.784350107433916, -4.5523897123399655, -4.408486923199402, -4.354140675475486, -4.353141939076286, -4.351645306899454, -4.34924786430514, -4.34364786991866, -4.3387909028516995, -4.338070652108377])
Dev_LL = np.array([-4.825858369089917, -4.651672134982936, -4.428373344200082, -4.335298253338358, -4.337009931381912, -4.3383182397905475, -4.352816187514511, -4.311967969348901, -4.339703167051308, -4.349601904605475])

3. manipulating --iterations from 1 to 100 while keeping --cluster_num 

ll_Train = [-4.737174745099106, -4.694913003395393, -4.628311747131087, -4.564498727187474, -4.5293567233438905, -4.503328680766495, -4.477741693816186, -4.4539833170066006, -4.434624379936848, -4.42003268706727, -4.4090417487385505, -4.400373168108383, -4.393377179475203, -4.38764143459839, -4.382597289318197, -4.377584593100297, -4.372232477482659, -4.366843699217973, -4.36243559980702, -4.359780943065891, -4.3584225680046265, -4.357592940312951, -4.356931118049575, -4.356332006382987, -4.35577892664377, -4.35528187004304, -4.354854905834882, -4.354505860358774, -4.354232959569776, -4.354026719514192, -4.353874115228674, -4.353762178271731, -4.35367990750515, -4.3536187816727745, -4.353572541261255, -4.3535367293816964, -4.353508231608212, -4.353484897289879, -4.3534652532884195, -4.353448296452931, -4.3534333464387895, -4.353419942588593, -4.353407772236407, -4.353396621174769, -4.3533863396851435, -4.353376819486321, -4.353367978337787, -4.3533597499953105, -4.353352077879679, -4.353344911281743, -4.353338203255294, -4.353331909588408, -4.353325988421981, -4.353320400218534, -4.3533151078854955, -4.353310076931931, -4.353305275591251, -4.353300674879032, -4.3532962485784985, -4.353291973159922, -4.353287827646879, -4.353283793444542, -4.353279854144604, -4.3532759953194065, -4.35327220431528, -4.353268470052423, -4.353264782836354, -4.353261134183967, -4.353257516665701, -4.353253923764231, -4.353250349749276, -4.353246789567631, -4.3532432387472255, -4.353239693313869, -4.353236149719313, -4.3532326047793015, -4.353229055620322, -4.353225499633961, -4.353221934437772, -4.353218357841777, -4.353214767819784, -4.353211162484813, -4.353207540068034, -4.35320389890069, -4.353200237398562, -4.353196554048599, -4.353192847397361, -4.353189116041054, -4.353185358616857, -4.353181573795392, -4.353177760274141, -4.35317391677168, -4.353170042022598, -4.35316613477301, -4.353162193776564, -4.353158217790881, -4.353154205574351, -4.353150155883248, -4.353146067469098, -4.353141939076286]
ll_Dev = [-4.801946512878894, -4.777583109960682, -4.718489387801333, -4.6573206543444625, -4.618526307619432, -4.581658839976368, -4.5429293399789685, -4.507730075123901, -4.479121554761542, -4.4559571596686665, -4.4365248040972425, -4.419852380908735, -4.405521688157962, -4.3934838870963, -4.383487128382887, -4.374679155802528, -4.366000302413134, -4.35710469488177, -4.349166913973307, -4.343837015616362, -4.340822190939238, -4.33895994389154, -4.337661368457459, -4.336732565761522, -4.336095814843689, -4.335695260434547, -4.335476002271014, -4.335385501432339, -4.335379703544323, -4.335426207119704, -4.335503141180069, -4.335596150455164, -4.335695773453653, -4.33579583965024, -4.335892554668148, -4.335983877344304, -4.336069007324138, -4.336147949357042, -4.33622116464938, -4.336289315087685, -4.336353092723924, -4.3364131186718735, -4.336469893531138, -4.336523783138854, -4.336575026569373, -4.336623756551228, -4.336670025296749, -4.336713831006887, -4.33675514206079, -4.3367939172134955, -4.336830121088742, -4.336863734933862, -4.336894763051892, -4.336923235587143, -4.336949208454657, -4.336972761209685, -4.336993993585471, -4.337013021316893, -4.337029971738402, -4.33704497951552, -4.337058182751764, -4.337069719613993, -4.337079725541111, -4.337088331043512, -4.337095660061188, -4.337101828824093, -4.337106945145758, -4.337111108077103, -4.337114407849335, -4.337116926040432, -4.337118735907354, -4.337119902834667, -4.337120484858711, -4.33712053323443, -4.3371200930192, -4.33711920365408, -4.337117899528257, -4.33711621051666, -4.337114162484218, -4.33711177775291, -4.337109075529873, -4.3371060722963115, -4.337102782158158, -4.337099217160116, -4.33709538756533, -4.337091302103101, -4.3370869681873385, -4.337082392108368, -4.337077579200698, -4.337072533989274, -4.337067260316515, -4.337061761452342, -4.337056040189192, -4.33705009892382, -4.337043939727552, -4.337037564406441, -4.3370309745526345, -4.33702417158815, -4.337017156802045, -4.337009931381912]


4.  set covariance = tied, cluster_num= 5, changed iterations from 1 to 100.

ll_Train = [-10.73140358901171, -10.589144983679036, -10.588966674525645, -10.588966476374539, -10.58896647615437, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127, -10.588966476154127]
ll_Dev = [-10.731448629198043, -10.589191051619983, -10.589012743570379, -10.5890125454205, -10.58901254520033, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085, -10.589012545200085]




5.  wang_em_gaussian.py --iteration 20 --print_params --clusters_file gaussian_smoketest_clusters.txt.
Gaussian
Train LL: -4.552389734806578
Dev LL: -4.651706055193873
Lambdas: 0.36882175428185343 | 0.6311782457181466
Mus: -0.22737992421509517 1.8136334951311712 | -1.1805834871756413 -2.000192336726504
Sigmas: 1.4040208615095888 0.5055266632646703 0.5055266632646702 1.0648471677338711 | 11.151199198748863 -1.8797380350125825 -1.879738035012582 4.023463053428506

6.wang_em_gaussian.py --nodev --iterations 100 --print_params --clusters_file gaussian_smoketest_clusters.txt.
Train LL: -4.5523897123399655
Lambdas: 0.36872598455254174 | 0.6312740154474583
Mus: -0.22727184582362153 1.8138983771895079 | -1.180502006337463 -1.9997684634745398
Sigmas: 1.4036407032923792 0.5054485593040766 0.5054485593040765 1.0645371711743972 | 11.149959997341842 -1.8791673237879176 -1.8791673237879176 4.024221568178133




